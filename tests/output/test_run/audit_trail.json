{
    "start_time": "2025-01-19T05:39:23.715762",
    "end_time": null,
    "total_duration_seconds": null,
    "input_file": null,
    "configuration": {},
    "final_metrics": {},
    "operations": [
        {
            "operation_name": "duplicate_handling",
            "description": "Remove duplicate rows from the dataset",
            "parameters": {
                "method": "auto"
            },
            "metrics": {
                "start_time": "2025-01-19T05:39:23.738037",
                "end_time": "2025-01-19T05:39:23.802507",
                "duration_seconds": 0.06447,
                "input_shape": [
                    10000,
                    12
                ],
                "output_shape": [
                    10000,
                    12
                ],
                "changes_made": {},
                "success": true,
                "error": null
            },
            "warnings": []
        },
        {
            "operation_name": "missing_value_handling",
            "description": "Handle missing values in the dataset",
            "parameters": {
                "numerical_method": "auto",
                "categorical_method": "auto"
            },
            "metrics": {
                "start_time": "2025-01-19T05:39:23.802507",
                "end_time": "2025-01-19T05:39:23.859609",
                "duration_seconds": 0.057102,
                "input_shape": [
                    10000,
                    12
                ],
                "output_shape": [
                    10000,
                    12
                ],
                "changes_made": {},
                "success": true,
                "error": null
            },
            "warnings": []
        },
        {
            "operation_name": "categorical_encoding",
            "description": "Encode categorical features",
            "parameters": {
                "method": [
                    "auto"
                ]
            },
            "metrics": {
                "start_time": "2025-01-19T05:39:23.859609",
                "end_time": "2025-01-19T05:39:23.917954",
                "duration_seconds": 0.058345,
                "input_shape": [
                    10000,
                    12
                ],
                "output_shape": [
                    10000,
                    12
                ],
                "changes_made": {
                    "dtype_changes": {
                        "country": {
                            "before": "object",
                            "after": "int64"
                        },
                        "gender": {
                            "before": "object",
                            "after": "int64"
                        }
                    }
                },
                "success": true,
                "error": null
            },
            "warnings": []
        },
        {
            "operation_name": "value_rounding",
            "description": "Round numerical values to appropriate precision",
            "parameters": {},
            "metrics": {
                "start_time": "2025-01-19T05:39:23.917954",
                "end_time": "2025-01-19T05:39:24.010892",
                "duration_seconds": 0.092938,
                "input_shape": [
                    10000,
                    12
                ],
                "output_shape": [
                    10000,
                    12
                ],
                "changes_made": {
                    "dtype_changes": {
                        "credit_score": {
                            "before": "int64",
                            "after": "Int64"
                        },
                        "tenure": {
                            "before": "int64",
                            "after": "Int64"
                        },
                        "customer_id": {
                            "before": "int64",
                            "after": "Int64"
                        },
                        "credit_card": {
                            "before": "int64",
                            "after": "Int64"
                        },
                        "country": {
                            "before": "int64",
                            "after": "Int64"
                        },
                        "active_member": {
                            "before": "int64",
                            "after": "Int64"
                        },
                        "churn": {
                            "before": "int64",
                            "after": "Int64"
                        },
                        "age": {
                            "before": "int64",
                            "after": "Int64"
                        },
                        "gender": {
                            "before": "int64",
                            "after": "Int64"
                        },
                        "products_number": {
                            "before": "int64",
                            "after": "Int64"
                        }
                    }
                },
                "success": true,
                "error": null
            },
            "warnings": []
        },
        {
            "operation_name": "Sensitive Feature Detection",
            "description": "Use AI to detect potentially sensitive features",
            "parameters": {},
            "metrics": {
                "start_time": "2025-01-19T05:39:24.076017",
                "end_time": "2025-01-19T05:40:04.922508",
                "duration_seconds": 40.846491,
                "input_shape": [
                    10000,
                    12
                ],
                "output_shape": [
                    10000,
                    12
                ],
                "changes_made": {
                    "sensitive_features": [
                        "credit_score",
                        "gender",
                        "balance",
                        "credit_card",
                        "estimated_salary"
                    ],
                    "results": [
                        {
                            "is_sensitive": false,
                            "sensibility_level": 1,
                            "justification": null,
                            "recommendation": null,
                            "column": "customer_id"
                        },
                        {
                            "is_sensitive": true,
                            "sensibility_level": 7,
                            "justification": "Credit scores are sensitive financial data that can reveal personal financial health and creditworthiness. They can be used to discriminate against individuals in financial services.",
                            "recommendation": "Anonymize or aggregate credit scores to reduce identifiability. Ensure compliance with financial data protection regulations like GDPR or CCPA.",
                            "column": "credit_score"
                        },
                        {
                            "is_sensitive": false,
                            "sensibility_level": 1,
                            "justification": null,
                            "recommendation": null,
                            "column": "country"
                        },
                        {
                            "is_sensitive": true,
                            "sensibility_level": 6,
                            "justification": "Gender is a protected characteristic and can lead to discrimination or bias in downstream applications, such as in predicting customer churn. It can also be used in conjunction with other data to re-identify individuals.",
                            "recommendation": "Consider anonymizing or aggregating gender data. Ensure that any models using this feature are regularly audited for bias. Implement strict access controls and data governance policies to protect this sensitive information.",
                            "column": "gender"
                        },
                        {
                            "is_sensitive": false,
                            "sensibility_level": 2,
                            "justification": "Age is a common demographic feature and is generally considered non-sensitive. It does not directly reveal personal or confidential information.",
                            "recommendation": "No special handling required. However, consider the context of use to ensure it does not contribute to age-based discrimination.",
                            "column": "age"
                        },
                        {
                            "is_sensitive": false,
                            "sensibility_level": 1,
                            "justification": "The 'tenure' feature represents the number of months a customer has been with the bank. This is non-sensitive, public information that does not reveal personal or confidential details.",
                            "recommendation": null,
                            "column": "tenure"
                        },
                        {
                            "is_sensitive": true,
                            "sensibility_level": 6,
                            "justification": "The 'balance' feature contains financial data, which is considered sensitive. While it does not directly identify individuals, it could potentially be used in combination with other features to re-identify customers or infer financial status.",
                            "recommendation": "Anonymize or aggregate the data to reduce the risk of re-identification. Ensure that access to this feature is restricted and that it is used in compliance with financial data protection regulations.",
                            "column": "balance"
                        },
                        {
                            "is_sensitive": false,
                            "sensibility_level": 0,
                            "justification": null,
                            "recommendation": null,
                            "column": "products_number"
                        },
                        {
                            "is_sensitive": true,
                            "sensibility_level": 9,
                            "justification": "The 'credit_card' feature contains binary data indicating the presence or absence of a credit card. While it does not directly reveal personal information, it is highly sensitive as it relates to financial data. This feature could be used in conjunction with other data to re-identify individuals or infer financial status, posing a high risk of privacy violation.",
                            "recommendation": "Consider anonymizing or aggregating this data to reduce the risk of re-identification. Ensure that access to this feature is restricted and that it is used only for legitimate purposes. Implement strong data security measures to protect this sensitive information.",
                            "column": "credit_card"
                        },
                        {
                            "is_sensitive": false,
                            "sensibility_level": 1,
                            "justification": null,
                            "recommendation": null,
                            "column": "active_member"
                        },
                        {
                            "is_sensitive": true,
                            "sensibility_level": 6,
                            "justification": "The 'estimated_salary' feature contains financial data, which is considered sensitive. While it does not directly identify individuals, it could potentially be used in combination with other data to re-identify individuals or infer personal financial status.",
                            "recommendation": "Consider anonymizing or aggregating the salary data to reduce the risk of re-identification. Access to this feature should be restricted and only provided to authorized personnel. Additionally, ensure compliance with relevant financial data protection regulations.",
                            "column": "estimated_salary"
                        }
                    ]
                },
                "success": true,
                "error": null
            },
            "warnings": []
        },
        {
            "operation_name": "Code Bias Analysis",
            "description": "Completed ai code bias analysis",
            "parameters": {
                "paths": [
                    "C:/Users/habib/Documents/AutoClean/tests/preprocessing"
                ],
                "analysis_type": "ai"
            },
            "metrics": {
                "start_time": "2025-01-19T05:40:04.925439",
                "end_time": "2025-01-19T05:40:45.236720",
                "duration_seconds": 40.311281,
                "input_shape": [
                    10000,
                    12
                ],
                "output_shape": [
                    10000,
                    12
                ],
                "changes_made": {
                    "results": [
                        {
                            "file": "C:\\Users\\habib\\Documents\\AutoClean\\tests\\preprocessing\\data_cleaner.py",
                            "analysis": {
                                "is_problematic": true,
                                "sensitivity_level": 8,
                                "problematic_sections": [
                                    {
                                        "code_snippet": "def remove_outliers_by_income(self, threshold: float = 100000) -> pd.DataFrame:\n    return self.df[self.df['income'] <= threshold]",
                                        "issue_type": "Data filtering",
                                        "explanation": "Removing records based on income threshold could disproportionately exclude certain demographics, particularly those in high-income brackets, which may correlate with specific racial or geographic groups."
                                    },
                                    {
                                        "code_snippet": "def encode_gender(self) -> pd.DataFrame:\n    gender_map = {'M': 1, 'F': 0}\n    self.df['gender'] = self.df['gender'].map(gender_map)",
                                        "issue_type": "Feature engineering",
                                        "explanation": "Binary encoding of gender reinforces gender binary assumptions and excludes non-binary individuals, potentially leading to discrimination and bias in the model."
                                    },
                                    {
                                        "code_snippet": "def reduce_females(self, ratio: float = 0.5) -> pd.DataFrame:\n    num_females = int(self.df[self.df['gender'] == 0].shape[0] * ratio)\n    return self.df[self.df['gender'] == 0].sample(num_females, random_state=42)",
                                        "issue_type": "Data filtering",
                                        "explanation": "Reducing the number of females in the dataset introduces gender bias, which could lead to unfair treatment and discrimination against females in the model's predictions."
                                    },
                                    {
                                        "code_snippet": "def filter_by_age(self, min_age: int = 18, max_age: int = 65) -> pd.DataFrame:\n    return self.df[(self.df['age'] >= min_age) & (self.df['age'] <= max_age)]",
                                        "issue_type": "Data filtering",
                                        "explanation": "Filtering by age range could introduce age-based discrimination, excluding younger or older individuals who may have different characteristics or needs."
                                    },
                                    {
                                        "code_snippet": "def normalize_education(self) -> pd.DataFrame:\n    edu_map = {\n        'Some High School': 0,\n        'High School': 1,\n        'Some College': 2,\n        'Bachelors': 3,\n        'Masters': 4,\n        'PhD': 5\n    }\n    self.df['education'] = self.df['education'].map(edu_map)",
                                        "issue_type": "Feature engineering",
                                        "explanation": "Simplification of education levels might disadvantage those with non-traditional education paths, leading to bias against individuals with alternative educational backgrounds."
                                    }
                                ],
                                "recommendations": [
                                    "Consider using more nuanced income thresholds or alternative methods to handle outliers without disproportionately affecting certain demographics.",
                                    "Expand gender encoding to include non-binary and other gender identities to avoid reinforcing gender binary assumptions.",
                                    "Avoid reducing the representation of any gender in the dataset to prevent gender bias.",
                                    "Use broader age ranges or consider the impact of age filtering on different demographic groups.",
                                    "Include more granular education categories or consider alternative ways to represent educational background to avoid disadvantaging non-traditional education paths."
                                ],
                                "severity": "high"
                            }
                        },
                        {
                            "file": "C:\\Users\\habib\\Documents\\AutoClean\\tests\\preprocessing\\feature_engineering.py",
                            "analysis": {
                                "is_problematic": true,
                                "sensitivity_level": 8,
                                "problematic_sections": [
                                    {
                                        "code_snippet": "self.df['wealth_score'] = (0.6 * self.df['income'] + 0.4 * self.df['assets'])",
                                        "issue_type": "Amplification of socioeconomic disparities",
                                        "explanation": "The creation of a wealth score based solely on income and assets may amplify existing socioeconomic disparities, as it does not account for other factors that might influence wealth distribution."
                                    },
                                    {
                                        "code_snippet": "self.df['high_income_area'] = self.df['neighborhood'].isin(high_income_areas).astype(int)",
                                        "issue_type": "Reinforcement of residential segregation",
                                        "explanation": "Labeling neighborhoods as high-income areas based on income thresholds can reinforce residential segregation patterns and socioeconomic biases."
                                    },
                                    {
                                        "code_snippet": "self.df['good_credit'] = (self.df['credit_score'] > 700).astype(int)",
                                        "issue_type": "Perpetuation of historical disadvantages",
                                        "explanation": "Creating a binary feature for 'good' credit based on a fixed threshold may perpetuate historical disadvantages faced by certain demographic groups, as credit scoring systems can be biased."
                                    },
                                    {
                                        "code_snippet": "self.df['education_score'] = (weights['degree_level'] * self.df['degree_level'] + weights['years_education'] * self.df['years_education'] + weights['test_scores'] * self.df['test_scores'])",
                                        "issue_type": "Disadvantage to non-traditional educational backgrounds",
                                        "explanation": "The education score may disadvantage individuals from non-traditional educational backgrounds or different cultural contexts, as it heavily weights degree level and test scores."
                                    }
                                ],
                                "recommendations": [
                                    "Consider including additional factors in the wealth score calculation to account for a more comprehensive view of wealth.",
                                    "Avoid labeling neighborhoods based solely on income thresholds; consider using a more nuanced approach that includes multiple socioeconomic indicators.",
                                    "Evaluate the credit scoring threshold and consider using a more dynamic or context-aware method to determine 'good' credit.",
                                    "Incorporate alternative educational metrics that account for non-traditional educational paths and cultural differences in the education score calculation."
                                ],
                                "severity": "high"
                            }
                        },
                        {
                            "file": "C:\\Users\\habib\\Documents\\AutoClean\\tests\\preprocessing\\sampling.py",
                            "analysis": {
                                "is_problematic": true,
                                "sensitivity_level": 7,
                                "problematic_sections": [
                                    {
                                        "code_snippet": "high_value = self.df[self.df['income'] >= income_threshold]",
                                        "issue_type": "Data Filtering",
                                        "explanation": "Filtering data based on income threshold could exclude lower-income groups, leading to representation bias and potentially unfair treatment of economically disadvantaged individuals."
                                    },
                                    {
                                        "code_snippet": "male = self.df[self.df['gender'] == 'M']\nfemale = self.df[self.df['gender'] == 'F']",
                                        "issue_type": "Gender Binary Reinforcement",
                                        "explanation": "The code reinforces a gender binary by only considering 'M' and 'F' genders, which excludes non-binary and other gender identities, leading to exclusion and misrepresentation."
                                    },
                                    {
                                        "code_snippet": "return train_test_split(self.df, test_size=test_size, stratify=self.df['education'], random_state=random_state)",
                                        "issue_type": "Stratification Bias",
                                        "explanation": "Stratifying only on education level might miss other important demographic factors and their intersections, potentially leading to biased model outcomes."
                                    },
                                    {
                                        "code_snippet": "age_group = self.df[(self.df['age'] >= min_age) & (self.df['age'] < max_age)]",
                                        "issue_type": "Age-Based Sampling",
                                        "explanation": "Sampling based on age groups could introduce age-based biases and ignore intersectional factors, leading to unfair treatment of certain age groups."
                                    }
                                ],
                                "recommendations": [
                                    "Consider including a broader range of income levels to avoid excluding economically disadvantaged groups.",
                                    "Expand gender categories to include non-binary and other gender identities to ensure inclusivity.",
                                    "Incorporate multiple demographic factors for stratification to capture intersectional effects.",
                                    "Ensure that age-based sampling considers intersectional factors and does not disproportionately affect certain age groups."
                                ],
                                "severity": "high"
                            }
                        }
                    ]
                },
                "success": true,
                "error": null
            },
            "warnings": []
        },
        {
            "operation_name": "Fairness Analysis credit_score",
            "description": "Analyze and mitigate bias for feature credit_score",
            "parameters": {},
            "metrics": {
                "start_time": "2025-01-19T05:40:45.241647",
                "end_time": "2025-01-19T05:40:45.277426",
                "duration_seconds": 0.035779,
                "input_shape": [
                    10000,
                    12
                ],
                "output_shape": [
                    10000,
                    12
                ],
                "changes_made": {
                    "results": {
                        "original": {
                            "disparate_impact": 1.1172327737252843,
                            "statistical_parity_difference": 0.02254930491594087,
                            "group_metrics": {
                                "group_0_positive_rate": 0.21489572989076464,
                                "group_1_positive_rate": 0.19234642497482377
                            }
                        },
                        "mitigated": {
                            "disparate_impact": 1.0,
                            "statistical_parity_difference": 0.0,
                            "group_metrics": {
                                "group_0_positive_rate": 0.21489572989076464,
                                "group_1_positive_rate": 0.19234642497482377
                            }
                        }
                    }
                },
                "success": true,
                "error": null
            },
            "warnings": []
        },
        {
            "operation_name": "Fairness Analysis gender",
            "description": "Analyze and mitigate bias for feature gender",
            "parameters": {},
            "metrics": {
                "start_time": "2025-01-19T05:40:45.278427",
                "end_time": "2025-01-19T05:40:45.294558",
                "duration_seconds": 0.016131,
                "input_shape": [
                    10000,
                    12
                ],
                "output_shape": [
                    10000,
                    12
                ],
                "changes_made": {
                    "results": {
                        "original": {
                            "disparate_impact": 1.5235566404076464,
                            "statistical_parity_difference": 0.08615610465201876,
                            "group_metrics": {
                                "group_0_positive_rate": 0.2507153863086066,
                                "group_1_positive_rate": 0.16455928165658787
                            }
                        },
                        "mitigated": {
                            "disparate_impact": 1.0,
                            "statistical_parity_difference": 0.0,
                            "group_metrics": {
                                "group_0_positive_rate": 0.2507153863086066,
                                "group_1_positive_rate": 0.16455928165658787
                            }
                        }
                    }
                },
                "success": true,
                "error": null
            },
            "warnings": []
        },
        {
            "operation_name": "Fairness Analysis balance",
            "description": "Analyze and mitigate bias for feature balance",
            "parameters": {},
            "metrics": {
                "start_time": "2025-01-19T05:40:45.295560",
                "end_time": "2025-01-19T05:40:45.310463",
                "duration_seconds": 0.014903,
                "input_shape": [
                    10000,
                    12
                ],
                "output_shape": [
                    10000,
                    12
                ],
                "changes_made": {
                    "results": {
                        "original": {
                            "disparate_impact": 0.6309047237790232,
                            "statistical_parity_difference": -0.0922,
                            "group_metrics": {
                                "group_0_positive_rate": 0.1576,
                                "group_1_positive_rate": 0.2498
                            }
                        },
                        "mitigated": {
                            "disparate_impact": 1.0000000000000002,
                            "statistical_parity_difference": 2.7755575615628914e-17,
                            "group_metrics": {
                                "group_0_positive_rate": 0.1576,
                                "group_1_positive_rate": 0.2498
                            }
                        }
                    }
                },
                "success": true,
                "error": null
            },
            "warnings": []
        },
        {
            "operation_name": "Fairness Analysis credit_card",
            "description": "Analyze and mitigate bias for feature credit_card",
            "parameters": {},
            "metrics": {
                "start_time": "2025-01-19T05:40:45.310463",
                "end_time": "2025-01-19T05:40:45.324727",
                "duration_seconds": 0.014264,
                "input_shape": [
                    10000,
                    12
                ],
                "output_shape": [
                    10000,
                    12
                ],
                "changes_made": {
                    "results": {
                        "original": {
                            "disparate_impact": 1.0312458270540432,
                            "statistical_parity_difference": 0.006306740995741661,
                            "group_metrics": {
                                "group_0_positive_rate": 0.20814940577249574,
                                "group_1_positive_rate": 0.20184266477675408
                            }
                        },
                        "mitigated": {
                            "disparate_impact": 0.9999999999999998,
                            "statistical_parity_difference": -5.551115123125783e-17,
                            "group_metrics": {
                                "group_0_positive_rate": 0.20814940577249574,
                                "group_1_positive_rate": 0.20184266477675408
                            }
                        }
                    }
                },
                "success": true,
                "error": null
            },
            "warnings": []
        },
        {
            "operation_name": "Fairness Analysis estimated_salary",
            "description": "Analyze and mitigate bias for feature estimated_salary",
            "parameters": {},
            "metrics": {
                "start_time": "2025-01-19T05:40:45.324727",
                "end_time": "2025-01-19T05:40:45.338575",
                "duration_seconds": 0.013848,
                "input_shape": [
                    10000,
                    12
                ],
                "output_shape": [
                    10000,
                    12
                ],
                "changes_made": {
                    "results": {
                        "original": {
                            "disparate_impact": 0.9548944337811901,
                            "statistical_parity_difference": -0.009399999999999992,
                            "group_metrics": {
                                "group_0_positive_rate": 0.199,
                                "group_1_positive_rate": 0.2084
                            }
                        },
                        "mitigated": {
                            "disparate_impact": 0.9999999999999998,
                            "statistical_parity_difference": -5.551115123125783e-17,
                            "group_metrics": {
                                "group_0_positive_rate": 0.199,
                                "group_1_positive_rate": 0.2084
                            }
                        }
                    }
                },
                "success": true,
                "error": null
            },
            "warnings": []
        },
        {
            "operation_name": "Fairness Analysis",
            "description": "Analyze and mitigate bias for each sensitive feature",
            "parameters": {},
            "metrics": {
                "start_time": "2025-01-19T05:40:45.240645",
                "end_time": "2025-01-19T05:40:45.338575",
                "duration_seconds": 0.09793,
                "input_shape": [
                    10000,
                    12
                ],
                "output_shape": [
                    10000,
                    12
                ],
                "changes_made": {
                    "results": {
                        "credit_score": {
                            "original": {
                                "disparate_impact": 1.1172327737252843,
                                "statistical_parity_difference": 0.02254930491594087,
                                "group_metrics": {
                                    "group_0_positive_rate": 0.21489572989076464,
                                    "group_1_positive_rate": 0.19234642497482377
                                }
                            },
                            "mitigated": {
                                "disparate_impact": 1.0,
                                "statistical_parity_difference": 0.0,
                                "group_metrics": {
                                    "group_0_positive_rate": 0.21489572989076464,
                                    "group_1_positive_rate": 0.19234642497482377
                                }
                            }
                        },
                        "gender": {
                            "original": {
                                "disparate_impact": 1.5235566404076464,
                                "statistical_parity_difference": 0.08615610465201876,
                                "group_metrics": {
                                    "group_0_positive_rate": 0.2507153863086066,
                                    "group_1_positive_rate": 0.16455928165658787
                                }
                            },
                            "mitigated": {
                                "disparate_impact": 1.0,
                                "statistical_parity_difference": 0.0,
                                "group_metrics": {
                                    "group_0_positive_rate": 0.2507153863086066,
                                    "group_1_positive_rate": 0.16455928165658787
                                }
                            }
                        },
                        "balance": {
                            "original": {
                                "disparate_impact": 0.6309047237790232,
                                "statistical_parity_difference": -0.0922,
                                "group_metrics": {
                                    "group_0_positive_rate": 0.1576,
                                    "group_1_positive_rate": 0.2498
                                }
                            },
                            "mitigated": {
                                "disparate_impact": 1.0000000000000002,
                                "statistical_parity_difference": 2.7755575615628914e-17,
                                "group_metrics": {
                                    "group_0_positive_rate": 0.1576,
                                    "group_1_positive_rate": 0.2498
                                }
                            }
                        },
                        "credit_card": {
                            "original": {
                                "disparate_impact": 1.0312458270540432,
                                "statistical_parity_difference": 0.006306740995741661,
                                "group_metrics": {
                                    "group_0_positive_rate": 0.20814940577249574,
                                    "group_1_positive_rate": 0.20184266477675408
                                }
                            },
                            "mitigated": {
                                "disparate_impact": 0.9999999999999998,
                                "statistical_parity_difference": -5.551115123125783e-17,
                                "group_metrics": {
                                    "group_0_positive_rate": 0.20814940577249574,
                                    "group_1_positive_rate": 0.20184266477675408
                                }
                            }
                        },
                        "estimated_salary": {
                            "original": {
                                "disparate_impact": 0.9548944337811901,
                                "statistical_parity_difference": -0.009399999999999992,
                                "group_metrics": {
                                    "group_0_positive_rate": 0.199,
                                    "group_1_positive_rate": 0.2084
                                }
                            },
                            "mitigated": {
                                "disparate_impact": 0.9999999999999998,
                                "statistical_parity_difference": -5.551115123125783e-17,
                                "group_metrics": {
                                    "group_0_positive_rate": 0.199,
                                    "group_1_positive_rate": 0.2084
                                }
                            }
                        }
                    }
                },
                "success": true,
                "error": null
            },
            "warnings": []
        }
    ]
}